{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking the excess rate vs trigger threshold\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "import mysql.connector\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import pymysql\n",
    "import os\n",
    "from matplotlib.offsetbox import AnchoredText"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieving the needed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is how we connect and put the mql command\n",
    "\n",
    "def query(command):\n",
    "    conn = mysql.connector.connect(user='xxxx',password='xxxxx',host='xxxx',database='xxxx',port='xxxx')\n",
    "    cursor = conn.cursor()    \n",
    "    result = pd.read_sql_query(command, conn)\n",
    "    conn.close()\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using your skills acquired up to now, build the command in order to be able to use the parameters for your calculations.\n",
    "\n",
    "There are three analysis tables from which fNumExcEvts could in principle be taken. \n",
    "Those are:\n",
    "- AnalysisResultsRunLP, the quicklook analysis, yielding results almost in real time, even if less precise\n",
    "- AnalysisResultsRunCutsLC for the new offline analysis \n",
    "- AnalysisResultsRunISDC of the old offline analysis\n",
    "\n",
    "For the trigger threshold, you want the most precise and recent one, fThresholdMinSet, if available. If it is empty for older runs, use fThresholdMedian.\n",
    "\n",
    "Have a look at the calculation of the excess rate below to find out which other parameters you need. \n",
    "Merge all parameters from the different tables to one on the common parameter RunId. \n",
    "\n",
    "Make sure you double check that merging went well and that the values are actually filled. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_exc_evts = df.fNumExcEvts.sum()\n",
    "\n",
    "raw_timedelta = df.fRunStop - df.fRunStart\n",
    "timedelta = raw_timedelta.dt.total_seconds()\n",
    "eff_timedelta = timedelta * df.fEffectiveOn\n",
    "time = eff_timedelta.sum()\n",
    "\n",
    "excess_rate = all_exc_evts * 3600 / time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you have plenty of time left, you can try and fit the plots with a function to come up with a Zenith- and trigger threshold-correction of the excess rate to calculate corrected light curves. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gammainclass",
   "language": "python",
   "name": "gammainclass"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
